{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","celltoolbar":"Slideshow","colab":{"name":"3_mlflow_experiments-2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"rise":{"scroll":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c826d34b2db24e7cacefdd8b50d2e5ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_512d806ab7624beea1ee2b3969980722","IPY_MODEL_54d04c5d9e2845f6887d72789ebebace","IPY_MODEL_f5e44c61db394e319ff014fced7be083"],"layout":"IPY_MODEL_15215ee5ac0642f8a3f621fa0d9d6454"}},"512d806ab7624beea1ee2b3969980722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f379f731a344a62b4b283260d176176","placeholder":"​","style":"IPY_MODEL_627dc9d70848499584bd4d47d045c0ec","value":"100%"}},"54d04c5d9e2845f6887d72789ebebace":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b3ee7d2ca69416fa58a4d3d4630b5e0","max":6119101,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c25596b56f9a49cc84f412daea4b3411","value":6119101}},"f5e44c61db394e319ff014fced7be083":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfc1c465cda64583a08e70f500616215","placeholder":"​","style":"IPY_MODEL_49eef76cc183430fa3808c194ab91fba","value":" 6119101/6119101 [00:38&lt;00:00, 159930.66it/s]"}},"15215ee5ac0642f8a3f621fa0d9d6454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f379f731a344a62b4b283260d176176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627dc9d70848499584bd4d47d045c0ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b3ee7d2ca69416fa58a4d3d4630b5e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c25596b56f9a49cc84f412daea4b3411":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cfc1c465cda64583a08e70f500616215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49eef76cc183430fa3808c194ab91fba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a6f4b9cce0543d5b41916ccc3ff66f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3e035bf325444feba243609cea147f4","IPY_MODEL_f2f80dc3a8e14c5e8e21f9a14f319fd1","IPY_MODEL_06b92ab0702d410fb75b2ec6c9f6d37d"],"layout":"IPY_MODEL_13c6d7c557534c2babd87e796578db14"}},"b3e035bf325444feba243609cea147f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ea505db0faf4355bd24a5c36184f2b4","placeholder":"​","style":"IPY_MODEL_ae0887376ffb40138befb39e2459a135","value":"100%"}},"f2f80dc3a8e14c5e8e21f9a14f319fd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_3890177ef71e48548bd5755712740d61","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_718891c3745b4e46a7f9b2d549ef5a1e","value":9999}},"06b92ab0702d410fb75b2ec6c9f6d37d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dce4ce2efe2477b9d4b89970c848db0","placeholder":"​","style":"IPY_MODEL_5a06bf42fa12462a9ed450871e465851","value":" 9999/10000 [00:00&lt;00:00, 21999.27it/s]"}},"13c6d7c557534c2babd87e796578db14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ea505db0faf4355bd24a5c36184f2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0887376ffb40138befb39e2459a135":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3890177ef71e48548bd5755712740d61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"718891c3745b4e46a7f9b2d549ef5a1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1dce4ce2efe2477b9d4b89970c848db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a06bf42fa12462a9ed450871e465851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"NnWdWeCfdspb"},"source":["# MLP para la clasificación de productos de Mercado Libre\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EtIz5h8M9kAN","executionInfo":{"elapsed":4453,"status":"ok","timestamp":1616338602006,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"fea90406-e579-471a-ed62-93654d3411a4"},"source":["!pip install PyDrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.1)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.27.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.7.2)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (54.1.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (20.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.12.4)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1n_Ki-399qx1"},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxKGDBeZ9sAo"},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDH5cMJJ-Z94"},"source":["mkdir -p data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaxpeqgJ9sIQ"},"source":["# Meli Data\n","downloaded = drive.CreateFile({'id':\"1TpzCRwb4hLMkPwlv1jNy1clpBBg0ajvL\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('./data/meli-challenge-2019.tar.bz2')        # replace the file name with your file\n","\n","# Diccionary\n","downloaded = drive.CreateFile({'id':\"11_zHF4AjPRUjkW_x9CFKJGiPBm6lCKO2\"})   # replace the id with id of file you want to access\n","downloaded.GetContentFile('./data/SBW-vectors-300-min5.txt.bz2')        # replace the file name with your file\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSZyetY5IkcE","executionInfo":{"elapsed":102128,"status":"ok","timestamp":1616338699735,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"d1605e81-ae3e-42e3-c03a-eb47f70fb309"},"source":["!nvcc --version"],"execution_count":null,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Wed_Jul_22_19:09:09_PDT_2020\n","Cuda compilation tools, release 11.0, V11.0.221\n","Build cuda_11.0_bu.TC445_37.28845127_0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"N8bubCrFI6d9","outputId":"66750219-ac2d-45f6-d1ae-c4f29987558d"},"source":["!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.7.1+cu110\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n","\u001b[K     |███████████████████████         | 834.1MB 1.3MB/s eta 0:04:16tcmalloc: large alloc 1147494400 bytes == 0x5615e17de000 @  0x7ffa77fac615 0x5615a7bdc06c 0x5615a7cbbeba 0x5615a7bdee8d 0x5615a7cd099d 0x5615a7c52fe9 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c52e50 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4f86a 0x5615a7cd17c6 0x5615a7c4eee2 0x5615a7cd17c6 0x5615a7c4eee2 0x5615a7cd17c6 0x5615a7c4eee2 0x5615a7cd17c6 0x5615a7d53431 0x5615a7cb4049 0x5615a7c1ec84 0x5615a7bdf8e9 0x5615a7c53ade 0x5615a7be069a 0x5615a7c4ea45 0x5615a7c4de0d 0x5615a7be077a 0x5615a7c4ea45 0x5615a7be069a 0x5615a7c4ea45\n","\u001b[K     |█████████████████████████████▏  | 1055.7MB 63.7MB/s eta 0:00:02tcmalloc: large alloc 1434370048 bytes == 0x561625e34000 @  0x7ffa77fac615 0x5615a7bdc06c 0x5615a7cbbeba 0x5615a7bdee8d 0x5615a7cd099d 0x5615a7c52fe9 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c52e50 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4f86a 0x5615a7cd17c6 0x5615a7c4eee2 0x5615a7cd17c6 0x5615a7c4eee2 0x5615a7cd17c6 0x5615a7c4eee2 0x5615a7cd17c6 0x5615a7d53431 0x5615a7cb4049 0x5615a7c1ec84 0x5615a7bdf8e9 0x5615a7c53ade 0x5615a7be069a 0x5615a7c4ea45 0x5615a7c4de0d 0x5615a7be077a 0x5615a7c4ea45 0x5615a7be069a 0x5615a7c4ea45\n","\u001b[K     |████████████████████████████████| 1156.7MB 50.6MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x56167b620000 @  0x7ffa77fac615 0x5615a7bdc06c 0x5615a7cbbeba 0x5615a7bdee8d 0x5615a7cd099d 0x5615a7c52fe9 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4ec9e 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4ec9e 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4ec9e 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4ec9e 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4ec9e 0x5615a7be069a 0x5615a7c4ec9e 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4f86a 0x5615a7c4db0e 0x5615a7be077a 0x5615a7c4f86a 0x5615a7c4db0e 0x5615a7be0e11\n","\u001b[K     |████████████████████████████████| 1156.8MB 6.4kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n","\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.8.0+cu101\n","    Uninstalling torch-1.8.0+cu101:\n","      Successfully uninstalled torch-1.8.0+cu101\n","Successfully installed torch-1.7.1+cu110\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6b-j_zgJI_mD","outputId":"a33c9219-be88-465e-e30f-d6c5d1a8ef93"},"source":["!pip install --upgrade gensim mlflow tqdm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting gensim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/afe2315e08a38967f8a3036bbe7e38b428e9b7a90e823a83d0d49df1adf5/gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n","\u001b[K     |████████████████████████████████| 24.2MB 137kB/s \n","\u001b[?25hCollecting mlflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/dc/b45061f1cde42465f8ac1ebd86db3253a0e155619929bf1d6de271317c08/mlflow-1.14.1-py3-none-any.whl (14.2MB)\n","\u001b[K     |████████████████████████████████| 14.2MB 47.5MB/s \n","\u001b[?25hCollecting tqdm\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/3e/2730d0effc282960dbff3cf91599ad0d8f3faedc8e75720fdf224b31ab24/tqdm-4.59.0-py2.py3-none-any.whl (74kB)\n","\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (4.2.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied, skipping upgrade: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.2)\n","Collecting gitpython>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 31.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.13)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.12.4)\n","Requirement already satisfied, skipping upgrade: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n","Collecting databricks-cli>=0.8.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/af/631375abc29e59cedfa4467a5f7755503ba19898890751e1f2636ef02f92/databricks-cli-0.14.3.tar.gz (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n","Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n","Collecting alembic<=1.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 46.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n","Collecting gunicorn; platform_system != \"Windows\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n","\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n","\u001b[?25hCollecting prometheus-flask-exporter\n","  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n","Collecting docker>=4.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/22/410313ad554477e87ec406d38d85f810e61ddb0d2fc44e64994857476de9/docker-4.4.4-py2.py3-none-any.whl (147kB)\n","\u001b[K     |████████████████████████████████| 153kB 55.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.23)\n","Collecting querystring-parser\n","  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n","Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n","Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.0->mlflow) (54.1.2)\n","Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n","Collecting Mako\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.4MB/s \n","\u001b[?25hCollecting python-editor>=0.3\n","  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n","Requirement already satisfied, skipping upgrade: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.9.0)\n","Collecting websocket-client>=0.32.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/33/80e0d4f60e84a1ddd9a03f340be1065a2a363c47ce65c4bd3bae65ce9631/websocket_client-0.58.0-py2.py3-none-any.whl (61kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask->mlflow) (1.1.1)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n","Building wheels for collected packages: databricks-cli, alembic, prometheus-flask-exporter\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-cp37-none-any.whl size=100557 sha256=00d4c926d50fdeb691d2cd8797c8f19e1e8a55fe019925d244d0819e4a9e158c\n","  Stored in directory: /root/.cache/pip/wheels/5b/24/f3/34d8e3964dac4ba849d844273c49a679111b00d5799ebb934a\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=90791db2e6858392ec662db8be084a3888854866cde443b7545db40ca901d400\n","  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n","  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp37-none-any.whl size=17159 sha256=6b74d08f515fcb2ff46c52e2d6756b6c0090bd78b1751160d5571b4011b80886\n","  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n","Successfully built databricks-cli alembic prometheus-flask-exporter\n","\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1+cu110 which is incompatible.\u001b[0m\n","Installing collected packages: gensim, smmap, gitdb, gitpython, databricks-cli, Mako, python-editor, alembic, gunicorn, prometheus-flask-exporter, websocket-client, docker, querystring-parser, mlflow, tqdm\n","  Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed Mako-1.1.4 alembic-1.4.1 databricks-cli-0.14.3 docker-4.4.4 gensim-3.8.3 gitdb-4.0.5 gitpython-3.1.14 gunicorn-20.0.4 mlflow-1.14.1 prometheus-flask-exporter-0.18.1 python-editor-1.0.4 querystring-parser-1.2.4 smmap-3.0.5 tqdm-4.59.0 websocket-client-0.58.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"v5kNQRHVJfcy","outputId":"f37e345e-7709-49c7-80eb-5cf8eb88dc33"},"source":["%%bash\n","\n","#mkdir -p data\n","#curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/meli-challenge-2019.tar.bz2 -o ./data/meli-challenge-2019.tar.bz2\n","#curl -L http://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2 -o ./data/SBW-vectors-300-min5.txt.bz2\n","tar jxvf ./data/meli-challenge-2019.tar.bz2 -C ./data/\n","bunzip2 ./data/SBW-vectors-300-min5.txt.bz2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["meli-challenge-2019/\n","meli-challenge-2019/spanish.train.csv.gz\n","meli-challenge-2019/portuguese.train.csv.gz\n","meli-challenge-2019/spanish.test.csv.gz\n","meli-challenge-2019/portuguese.test.csv.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ktVyHsH09zSg","outputId":"4f731313-c16b-49a1-dbac-f669a4d8c4cd"},"source":["# para ahicar el dataset de train \n","# Acordate de corregir en las funciones de prepocesamiento\n","\n","%%bash\n","\n","zcat ./data/meli-challenge-2019/spanish-train.csv.gz | head -n 1000000 | gzip > ./data/meli-challenge-2019/spanish-train-debug.csv.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gzip: ./data/meli-challenge-2019/spanish-train.csv.gz: No such file or directory\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"rPCr9MO6II6T"},"source":["# MLflow y un experimento sencillo"]},{"cell_type":"markdown","metadata":{"id":"kddqPiDXII6o"},"source":["## Librerías"]},{"cell_type":"code","metadata":{"id":"90_qJ5S7II6t"},"source":["import gzip\n","import mlflow\n","import pandas as pd\n","import tempfile\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from gensim import corpora\n","from gensim.models import KeyedVectors\n","from gensim.parsing import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import balanced_accuracy_score\n","from torch.utils.data import IterableDataset, DataLoader\n","from tqdm.notebook import tqdm, trange"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3WlND7adII6x"},"source":["## Dataset\n","\n","Nos basaremos en el dataset que creamos para el [notebook 2](./2_datasets.ipynb), con la diferencia de que pasaremos el dataframe de manera directa (esto es para poder hacer split en train/test)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lllg749lNlzn","executionInfo":{"elapsed":433842,"status":"ok","timestamp":1616157909032,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"e62cf090-540e-43d4-8595-59fd5717c22d"},"source":["!zcat ./data/meli-challenge-2019/spanish.train.csv.gz | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6119101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c826d34b2db24e7cacefdd8b50d2e5ed","512d806ab7624beea1ee2b3969980722","54d04c5d9e2845f6887d72789ebebace","f5e44c61db394e319ff014fced7be083","15215ee5ac0642f8a3f621fa0d9d6454","1f379f731a344a62b4b283260d176176","627dc9d70848499584bd4d47d045c0ec","0b3ee7d2ca69416fa58a4d3d4630b5e0","c25596b56f9a49cc84f412daea4b3411","cfc1c465cda64583a08e70f500616215","49eef76cc183430fa3808c194ab91fba"]},"id":"E9IO1T3fN3WY","executionInfo":{"elapsed":471812,"status":"ok","timestamp":1616157947434,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"a7b8a072-9ef3-4f4e-c29b-3922e08b989a"},"source":["import numpy as np\n","\n","train_index = np.random.rand(6119101) <= 0.8\n","\n","with gzip.open(\"./data/meli-challenge-2019/spanish.train.csv.gz\", \"rt\") as spanish_corpus,\\\n","    gzip.open(\"./data/meli-challenge-2019/spanish-train.csv.gz\", \"wt\") as spanish_train,\\\n","    gzip.open(\"./data/meli-challenge-2019/spanish-validation.csv.gz\", \"wt\") as spanish_validation:\n","  for idx, line in enumerate(tqdm(spanish_corpus, total=6119101)):\n","    if train_index[idx]:\n","      spanish_train.write(line)\n","    else:\n","      spanish_validation.write(line)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c826d34b2db24e7cacefdd8b50d2e5ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6119101 [00:00<?, ?it/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JzBSw8vRQHq7","executionInfo":{"elapsed":474877,"status":"ok","timestamp":1616157950890,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"6b7770cb-5c5c-475f-9197-d9f39f703128"},"source":["!zcat ./data/meli-challenge-2019/spanish-train.csv.gz | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4895870\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U8e6QI5TQ5dd","executionInfo":{"elapsed":2144,"status":"ok","timestamp":1616157953065,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"076215b9-6af5-4f39-ca0c-acb59cdc4a71"},"source":["!zcat ./data/meli-challenge-2019/spanish-validation.csv.gz | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1223231\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCjsD1_Gj-fe","executionInfo":{"elapsed":2115,"status":"ok","timestamp":1616157953065,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"f0cc3de6-95e8-4abc-acae-4a2c004fb905"},"source":["!zcat ./data/meli-challenge-2019/spanish.test.csv.gz | wc -l"],"execution_count":null,"outputs":[{"output_type":"stream","text":["63681\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNZedus7RwVE","executionInfo":{"elapsed":2559,"status":"ok","timestamp":1616157953537,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"24977253-6427-4cd1-8d65-72f5d22885c5"},"source":["!zcat ./data/meli-challenge-2019/spanish-validation.csv.gz | head"],"execution_count":null,"outputs":[{"output_type":"stream","text":["spanish,reliable,Cómoda Toillete Escritorio Y Mesas De Luz Reina Ana Roble ,DRAWERS\n","spanish,reliable,Casio Fx 19 - Calculadora Cientifica,CALCULATORS\n","spanish,reliable,Mochila Las Oreiro Original!súper Oferta!envio Gratis!,BACKPACKS\n","spanish,reliable,Controlador Fiscal Homologado Elitronic Cr-50 *envío Gratis*,PRINTERS\n","spanish,reliable,Rifle Fox Pr900w Pcp Mira Cargador Doble Inflador Correa,AIRSOFT_GUNS\n","spanish,reliable,Rolling Stone 91 Rolling Stones,MAGAZINES\n","spanish,reliable,Armazones De Lectura Emporio Armani 100 % Original 9512,GLASSES_FRAMES\n","spanish,reliable,Memoria Pc 8gb Kingston Hyperx Fury Ddr3 1600mhz Azul,RAM_MEMORY_MODULES\n","spanish,reliable,Dimm 128mb 4 Chips 133,RAM_MEMORY_MODULES\n","spanish,reliable,\"Bajo Performer By Spector, Muy Buen Estado!\",BASS_GUITARS\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tVbxLZBrII6z"},"source":["import csv\n","import random\n","\n","class MeliChallengeDataset(IterableDataset):\n","    def __init__(self,\n","                 dataset_path,\n","                 dataset_size,\n","                 random_buffer_size=2048,\n","                 transform=None):\n","        assert random_buffer_size > 0\n","        self.dataset_path = dataset_path\n","        self.dataset_size = dataset_size\n","        self.random_buffer_size = random_buffer_size\n","        self.transform = transform\n","    \n","    def __len__(self):\n","        return self.dataset_size\n","\n","    def __iter__(self):\n","        try:\n","            with gzip.open(self.dataset_path, \"rt\") as dataset:\n","                shuffle_buffer = []\n","                csv_reader = csv.reader(dataset)\n","                next(csv_reader)\n","\n","                for line in csv_reader:\n","                    _, label_quality, title, category = line\n","\n","                    if self.random_buffer_size == 1:\n","                        item = {\n","                            \"title\": f\"{label_quality} {title}\",\n","                            \"category\": category\n","                        }\n","                        if self.transform:\n","                            item = self.transform(item)\n","                        yield item\n","                    else:\n","                        shuffle_buffer.append({\n","                            \"title\": f\"{label_quality} {title}\",\n","                            \"category\": category\n","                        })\n","\n","                        if len(shuffle_buffer) == self.random_buffer_size:\n","                            random.shuffle(shuffle_buffer)\n","                            for item in shuffle_buffer:\n","                                if self.transform:\n","                                    item = self.transform(item)\n","                                yield item\n","                            shuffle_buffer = []\n","\n","            if len(shuffle_buffer) > 0:\n","                random.shuffle(shuffle_buffer)\n","                for item in shuffle_buffer:\n","                    if self.transform:\n","                        item = self.transform(item)\n","                    yield item\n","        except GeneratorExit:\n","            return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cBQbHs9YII61"},"source":["## Preprocesamiento\n","\n","En este caso vamos a utilizar un sólo módulo para transformar los datos de MeLi. Este se encargará de preprocesar el texto (i.e. normalizarlo) y transformará las palabras en índices de un diccionario para luego poder pasar una secuencia de palabras para buscar en la matriz de embeddings y así permitir mayor manipulación de los embeddings (en lugar de utilizar embeddings fijos)."]},{"cell_type":"code","metadata":{"id":"znRL2FAFII63"},"source":["class RawDataProcessor:\n","    def __init__(self, \n","                 dataset_path,\n","                 dataset_size,\n","                 ignore_header=True, \n","                 filters=None, \n","                 vocab_size=50000):\n","        if filters:\n","            self.filters = filters\n","        else:\n","            self.filters = [\n","                lambda s: s.lower(),\n","                preprocessing.strip_tags,\n","                preprocessing.strip_punctuation,\n","                preprocessing.strip_multiple_whitespaces,\n","                preprocessing.strip_numeric,\n","                preprocessing.remove_stopwords,\n","                preprocessing.strip_short,\n","            ]\n","        \n","        # Create dictionary based on all the reviews (with corresponding preprocessing)\n","        self.dictionary = corpora.Dictionary()\n","        labels = set()\n","\n","        with gzip.open(dataset_path, \"rt\") as dataset:\n","            csv_reader = csv.reader(dataset)\n","            if ignore_header:\n","              next(csv_reader)\n","            for line in tqdm(csv_reader, total=dataset_size):\n","                _, label_quality, title, category = line\n","                self.dictionary.add_documents(\n","                    [self._preprocess_string(f\"{label_quality} {title}\")]\n","                )\n","                labels.add(category)\n","        # Filter the dictionary and compactify it (make the indices continous)\n","        self.dictionary.filter_extremes(no_below=2, no_above=1, keep_n=vocab_size)\n","        self.dictionary.compactify()\n","        # Add a couple of special tokens\n","        self.dictionary.patch_with_special_tokens({\n","            \"[PAD]\": 0,\n","            \"[UNK]\": 1\n","        })\n","        self.idx_to_target = sorted(labels)\n","        self.target_to_idx = {t: i for i, t in enumerate(self.idx_to_target, start=1)}\n","\n","    def _preprocess_string(self, string):\n","        return preprocessing.preprocess_string(string, filters=self.filters)\n","\n","    def _sentence_to_indices(self, sentence):\n","        return self.dictionary.doc2idx(sentence, unknown_word_index=1)\n","    \n","    def encode_data(self, data):\n","        return self._sentence_to_indices(self._preprocess_string(data))\n","    \n","    def encode_target(self, target):\n","        return self.target_to_idx.get(target, 0)\n","    \n","    def __call__(self, item):\n","        if isinstance(item, list):\n","          data = [self.encode_data(i[\"title\"]) for i in item]\n","          target = [self.encode_target(i[\"category\"]) for i in item]\n","        else:\n","          data = self.encode_data(item[\"title\"])\n","          target = self.encode_target(item[\"category\"])\n","        \n","        return {\n","            \"data\": data,\n","            \"target\": target\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8AbIHdyII66"},"source":["## Lectura de datos\n","\n","En esta ocasión, leeremos los datos de MeLi y lo dividiremos en subconjuntos de entrenamiento y evaluación."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3a6f4b9cce0543d5b41916ccc3ff66f2","b3e035bf325444feba243609cea147f4","f2f80dc3a8e14c5e8e21f9a14f319fd1","06b92ab0702d410fb75b2ec6c9f6d37d","13c6d7c557534c2babd87e796578db14","0ea505db0faf4355bd24a5c36184f2b4","ae0887376ffb40138befb39e2459a135","3890177ef71e48548bd5755712740d61","718891c3745b4e46a7f9b2d549ef5a1e","1dce4ce2efe2477b9d4b89970c848db0","5a06bf42fa12462a9ed450871e465851"]},"id":"nj-o2dLDXnIh","executionInfo":{"elapsed":1006,"status":"ok","timestamp":1616161106007,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"1554bd43-51cd-4b48-eeb3-e805ca9e33c6"},"source":["preprocess = RawDataProcessor(\n","    \"./data/meli-challenge-2019/spanish-train-debug.csv.gz\",\n","    10000\n","#    preprocessing_buffer_size=100000\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a6f4b9cce0543d5b41916ccc3ff66f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10000 [00:00<?, ?it/s]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXGI-9rGII68","executionInfo":{"elapsed":534,"status":"ok","timestamp":1616161106008,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"5a762751-bbc6-4e22-cb39-7a2523fed4f0"},"source":["train_dataset = MeliChallengeDataset(\n","    \"./data/meli-challenge-2019/spanish-train-debug.csv.gz\",\n","    10000,\n","    random_buffer_size=2048,\n","    transform=preprocess\n",")\n","validation_dataset = MeliChallengeDataset(\n","    \"./data/meli-challenge-2019/spanish-validation.csv.gz\",\n","    1224416,\n","    random_buffer_size=1,\n","    transform=preprocess\n",")\n","\n","test_dataset = MeliChallengeDataset(\n","    \"./data/meli-challenge-2019/spanish.test.csv.gz\",\n","    63681,\n","    random_buffer_size=1,\n","    transform=preprocess\n",")\n","\n","print(f\"Datasets loaded with {len(train_dataset)} training elements and {len(validation_dataset)} validation elements\")\n","print(f\"Sample train element:\\n{next(iter(train_dataset))}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Datasets loaded with 10000 training elements and 1224416 validation elements\n","Sample train element:\n","{'data': [4, 436, 437, 1, 299], 'target': 342}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RD729TXbII7A"},"source":["## Collation function\n","\n","Como en este caso trabajamos con secuencias de palabras (representadas por sus índices en un vocabulario), cuando queremos buscar un *batch* de datos, el `DataLoader` de PyTorch espera que los datos del *batch* tengan la misma dimensión (para poder llevarlos todos a un tensor de dimensión fija). Esto lo podemos lograr mediante el parámetro de `collate_fn`. En particular, esta función se encarga de tomar varios elementos de un `Dataset` y combinarlos de manera que puedan ser devueltos como un tensor de PyTorch. Muchas veces la `collate_fn` que viene por defecto en `DataLoader` sirve (como se vio en el notbook 2), pero este no es el caso. Se define un módulo `PadSequences` que toma un valor mínimo, opcionalmente un valor máximo y un valor de relleno (*pad*) y dada una lista de secuencias, devuelve un tensor con *padding* sobre dichas secuencias."]},{"cell_type":"code","metadata":{"id":"Vj-BVoL7II7D"},"source":["class PadSequences:\n","    def __init__(self, pad_value=0, max_length=None, min_length=1):\n","        assert max_length is None or min_length <= max_length\n","        self.pad_value = pad_value\n","        self.max_length = max_length\n","        self.min_length = min_length\n","\n","    def __call__(self, items):\n","        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n","        seq_lengths = [len(d) for d in data]\n","\n","        if self.max_length:\n","            max_length = self.max_length\n","            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n","        else:\n","            max_length = max(self.min_length, max(seq_lengths))\n","\n","        data = [d[:l] + [self.pad_value] * (max_length - l)\n","                for d, l in zip(data, seq_lengths)]\n","            \n","        return {\n","            \"data\": torch.LongTensor(data),\n","            \"target\": torch.LongTensor(target)\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pGkw7ToII7G"},"source":["## DataLoaders\n","\n","Ya habiendo definido nuestros conjuntos de datos y nuestra `collation_fn`, podemos definir nuestros `DataLoader`s, uno para entrenamiento y otro para evaluación. Ver que la diferencia fundamental está en `shuffle`, no queremos mezclar los valores de evaluación cada vez que evaluamos porque al evaluar mediante *mini-batchs* nos puede generar inconsistencias."]},{"cell_type":"code","metadata":{"id":"ImFb-KIrII7H","scrolled":true},"source":["# Batch size modificado. Original 128\n","\n","pad_sequences = PadSequences()\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False,\n","                          collate_fn=pad_sequences, drop_last=False)\n","validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False,\n","                               collate_fn=pad_sequences, drop_last=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,\n","                               collate_fn=pad_sequences, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eCbNOu-IcPoK","executionInfo":{"elapsed":831,"status":"ok","timestamp":1616158183782,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"cc4b90bb-2f1c-46db-ec2c-22eab6207a3f"},"source":["next(iter(train_loader))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'data': tensor([[   4, 2418,    1, 2417,    1, 2418,    1, 2417,  962,    0],\n","         [   4,  236,  237,  235,    1,  234,  232,  231,  233,    0],\n","         [   4, 1186, 2095, 1517,    0,    0,    0,    0,    0,    0],\n","         [   4, 1698,    1, 1388,    1, 2450,    1, 1126,  892,    0],\n","         [   4,  447,  672, 2836,  360,    0,    0,    0,    0,    0],\n","         [   4,  767,  759,  299,  768,   97,    0,    0,    0,    0],\n","         [   4,  569, 2094,  327, 2092, 2093, 1287,    0,    0,    0],\n","         [   4, 1158,    1, 2072,  354,  283,    0,    0,    0,    0],\n","         [   4,    1,  498,  781,  353,  299,    0,    0,    0,    0],\n","         [   4, 1737,  507, 2942, 2946,  638, 1906,    0,    0,    0],\n","         [   4,  168,  165,  525,  846,  166,   99,  164,  937,    0],\n","         [   4,  336,    1,  762,    1,  777,    1,  381,  776,    0],\n","         [   4,  176,  833,  447,  832,  831, 1517, 2570,    0,    0],\n","         [   4,  118, 1244, 1277, 1742,  120, 1743,    0,    0,    0],\n","         [   4, 1429,  166, 1430,  674,  943,    0,    0,    0,    0],\n","         [   4, 2082,  211, 2080,  121, 2081,    0,    0,    0,    0],\n","         [   4, 1429,  166, 1430, 1438,    0,    0,    0,    0,    0],\n","         [   4,   40,  166, 2886, 2885,  121,    1, 2884,    0,    0],\n","         [   4,  786,  592,  245,   39,    0,    0,    0,    0,    0],\n","         [   4,  314, 1388, 3073,  367,    1,    1, 1061,    1,  644],\n","         [   4, 1103,  483,    1,    0,    0,    0,    0,    0,    0],\n","         [   4,    1,  582,    1,    1,    0,    0,    0,    0,    0],\n","         [   4,  359,  448,  271, 1042, 1074,    1, 1132,    0,    0],\n","         [   4, 3299, 3496, 3495,    1,    1,    1,    1,    0,    0],\n","         [   4,  578,  216,    2,  121,  144,    0,    0,    0,    0],\n","         [   4,  954,  960, 2071,  598,    0,    0,    0,    0,    0],\n","         [   4,  710, 1527, 1334, 1529, 1528,  347,    0,    0,    0],\n","         [   4,  574,   15,    1,  626,  625,    0,    0,    0,    0],\n","         [   4,  151,  149,  152,  150,  155,  153,  154,    0,    0],\n","         [   4,  734, 3122, 1601, 3123,    0,    0,    0,    0,    0],\n","         [   4,    1,    1,  933,  596,    0,    0,    0,    0,    0],\n","         [   4, 1070, 1746,  241, 1177, 1747, 1745,  657, 1748,    0],\n","         [   4,  296,    1,    1,  176, 2084,   95, 2083,    1,    0],\n","         [   4,  373, 1887, 3120,  268,  423,  180,  596,  371,  706],\n","         [   4,  225,  268,  266,  267,  269,  265,    1,    0,    0],\n","         [   4, 1147, 1705,    0,    0,    0,    0,    0,    0,    0],\n","         [   4,  201,    1,  327,    1,    1,    0,    0,    0,    0],\n","         [   4, 1809,  271, 1332,  596,  378, 1330,    0,    0,    0],\n","         [   4, 1108, 1579, 1613,    1, 1611,    0,    0,    0,    0],\n","         [   4,  881,   13,   12,  111, 1621,   14,    0,    0,    0],\n","         [   4,  300,    1, 2406,    1,  562,  403,  101,    0,    0],\n","         [   4, 3482, 3481,    1,    1,    1,    0,    0,    0,    0],\n","         [   4, 1249,  121, 2640,    1, 1058,    0,    0,    0,    0],\n","         [   4,  219, 2964,  163,    0,    0,    0,    0,    0,    0],\n","         [   4,  241, 1220,  439,  183,    0,    0,    0,    0,    0],\n","         [   4, 1108, 1579, 1062, 1580,    0,    0,    0,    0,    0],\n","         [   4,    1,  118,  120, 1509,    1,    0,    0,    0,    0],\n","         [   4,  176, 2962, 2963,    1,  830,  378, 2961,    0,    0],\n","         [   4,  238,  121,  582,  512, 2193, 1407,    0,    0,    0],\n","         [   4,  154,    1, 1127, 2776,  574,  121,   80,    0,    0],\n","         [   4, 3121,    1,  558,  611,  557, 1362,  738,    0,    0],\n","         [   4, 2651, 2900, 3090, 3089,    1,    1,  894, 2758,    0],\n","         [   4, 1172,    1,  363, 1173,    0,    0,    0,    0,    0],\n","         [   4,  392, 2388, 2387,  723,  952,  546, 1404,    0,    0],\n","         [   4,  772,  363, 1984, 2425,    0,    0,    0,    0,    0],\n","         [   4, 2584,  791, 3386,   35, 3387, 2583,    0,    0,    0],\n","         [   4, 2006, 2733, 2734, 2735, 2736,    1,    0,    0,    0],\n","         [   4,  315, 2436,  666,    1,    0,    0,    0,    0,    0],\n","         [   4,  170,  847,  565, 1155,  165, 3483,  616,    0,    0],\n","         [   4, 3438,    1, 1262,  398,   83,    0,    0,    0,    0],\n","         [   4,   20,   22,   21,    1,   23,    0,    0,    0,    0],\n","         [   4, 1643,  310, 1217, 1419,   88,   16,    0,    0,    0],\n","         [   4,  118, 1250, 1248,   95, 1249,    0,    0,    0,    0],\n","         [   4,  196,  249,  246,  248,  245,  247,  243,  244,    0]]),\n"," 'target': tensor([243, 380,  23,  87,  24,  42, 162, 360, 477, 282, 118, 520, 527, 169,\n","          90, 480,  90, 433, 379, 596,   8, 196, 502,  75, 260, 595, 194, 248,\n","         590, 452, 100,  50, 187,  60, 521, 256, 185, 456, 115, 252, 147, 556,\n","         153,  14, 124, 115,  81, 526, 308, 447, 461,  84, 315, 344, 315, 411,\n","          83, 149, 118, 568, 105, 494, 348, 158])}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2yub4ey60kw","executionInfo":{"elapsed":507,"status":"ok","timestamp":1616158184151,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"970fdf15-b50f-43ef-8522-66278d1f4c05"},"source":["next(iter(validation_loader))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'data': tensor([[   4,  634, 1773, 3338,    0,    0,    0,    0,    0,    0],\n","         [   4,  145, 2132,    1,    9, 2494,  213,  365,  281,    0],\n","         [   4,  772,    1,    1,    1,  279,  281,    0,    0,    0],\n","         [   4, 1103, 1867,    1, 1548, 2634,  786,  245, 4752, 1407],\n","         [   4, 1521, 1522, 1521,    1,    0,    0,    0,    0,    0],\n","         [   4,  602, 4551,    1, 5222,    9,    0,    0,    0,    0],\n","         [   4,  613,  612, 2008,  857,  611,  557,  432,    0,    0],\n","         [   4,  556,    1,    0,    0,    0,    0,    0,    0,    0],\n","         [   4, 1016,    1,    1, 1474, 2360,  430,    0,    0,    0],\n","         [   4,  585, 2564, 2563, 2616,    1,    0,    0,    0,    0],\n","         [   4, 1348, 2058,  541, 1739, 2267,  142,    0,    0,    0],\n","         [   4,  864, 1355,  514, 1110, 1019,    1,    1,    0,    0],\n","         [   4,    1, 1270, 4937,    1,    1,    1,    0,    0,    0],\n","         [   4, 5632, 1214, 1419, 2264, 1002, 2528,    0,    0,    0],\n","         [   4, 5484, 1002,    1, 1128,    1,    1,  394, 2290,    0],\n","         [   4,  328, 2267,    1, 2844,  103,  324,    0,    0,    0],\n","         [   4, 3428,  733,  477,  666,  666, 2646, 1696,    0,    0],\n","         [   4, 1282, 2383,   86,  704, 1930,   53,    0,    0,    0],\n","         [   4, 2830, 2831,  630,    1, 3343,    0,    0,    0,    0],\n","         [   4,  315, 3533, 4127, 1817,  192,    9,    0,    0,    0],\n","         [   4, 2344,  665,    1,    1,    1,    0,    0,    0,    0],\n","         [   4,  506,  369,    1,  213,    0,    0,    0,    0,    0],\n","         [   4, 1505, 1569,  782,  271, 3951,    1,    0,    0,    0],\n","         [   4,  438,  165,    0,    0,    0,    0,    0,    0,    0],\n","         [   4, 3379,    1,  443,    1, 2524,    1, 2537,    0,    0],\n","         [   4,  582,  729,    1, 3228, 1029, 3677, 3135,    1,    0],\n","         [   4, 2400, 4323, 1719, 5215,  677,  409,    0,    0,    0],\n","         [   4, 3993, 1319, 3050, 3727,    0,    0,    0,    0,    0],\n","         [   4, 3357, 3309, 2419,    1,  837, 5504,    0,    0,    0],\n","         [   4,    1,    1, 1816,    1,  300,  876,    1,    0,    0],\n","         [   4, 1441,    1,    1,    1, 1696,    0,    0,    0,    0],\n","         [   4, 3781,    1,  633, 2631,    1,    0,    0,    0,    0],\n","         [   4,  305, 1770,    1, 1523,    1,  876,    1,    1,    0],\n","         [   4,  138,  842,   26, 1183,   31,    0,    0,    0,    0],\n","         [   4,  315,    1, 3938,    1,    1,  166,    1,    0,    0],\n","         [   4,  338,    1,    1,   78, 2389,    0,    0,    0,    0],\n","         [   4, 1084,  121,  631,  514,  118,    0,    0,    0,    0],\n","         [   4,  355,    1,  702,   78,    1,    0,    0,    0,    0],\n","         [   4,  447, 2327,  300, 2016, 3034,    1, 3132,    0,    0],\n","         [   4,    1,  516,  720, 1421, 3291, 1474,    1,    0,    0],\n","         [   4, 1011,    1,    1,    0,    0,    0,    0,    0,    0],\n","         [   4, 2534,  212, 3210,  103,    0,    0,    0,    0,    0],\n","         [   4, 4312, 1741, 4987,    1, 3691, 2120,   63,    0,    0],\n","         [   4,  336,  149,  360, 1189,   27,    0,    0,    0,    0],\n","         [   4, 4004, 4777,  190, 1358, 5234,    0,    0,    0,    0],\n","         [   4,  565,    1, 4121,  140,    1, 2230, 2043,    0,    0],\n","         [   4, 1630,    1,    0,    0,    0,    0,    0,    0,    0],\n","         [   4,  225,    1,   41,    1,    0,    0,    0,    0,    0],\n","         [   4, 1292, 1851,  267, 1024, 1957,    0,    0,    0,    0],\n","         [   4,  954,  767,    1, 5463, 1197,    1, 1748, 2000, 4387],\n","         [   4,  763,   53, 5633,  166,  559,    1,    0,    0,    0],\n","         [   4, 3509,   88, 1299,  757,  756,    1, 1404,    0,    0],\n","         [   4, 1773,    1, 1595, 1774,    0,    0,    0,    0,    0],\n","         [   4, 3278, 3277, 2539,    1,    0,    0,    0,    0,    0],\n","         [   4,  640,    1,    1, 2234, 4283,    0,    0,    0,    0],\n","         [   4, 1391,  616,  979, 1605, 1606,    0,    0,    0,    0],\n","         [   4,   90,  434, 2598, 2597,  827,    0,    0,    0,    0],\n","         [   4, 1268, 1823, 3805, 1090,   78, 1833,    0,    0,    0],\n","         [   4,  359, 2223,  228,  536,    0,    0,    0,    0,    0],\n","         [   4,  570, 1172,   36,    0,    0,    0,    0,    0,    0],\n","         [   4,   64, 2061, 1940,   65,    0,    0,    0,    0,    0],\n","         [   4,  373,  121,  175, 1888,    1,    0,    0,    0,    0],\n","         [   4,    1,   18,    1, 2673,    1,    1,    0,    0,    0],\n","         [   4,  858,  406,  404, 3001,    1,    1,  858, 2113,    0]]),\n"," 'target': tensor([ 97,  54, 456,   8, 351, 268, 461, 461,  59, 141, 467, 573, 280, 124,\n","         456, 467, 458, 378, 108, 149, 542, 282,  55, 238, 226,   3,  54, 457,\n","         246, 357,  81,  40, 314, 294, 149, 510, 113, 388, 424, 338, 351, 368,\n","           4,  37, 115, 343, 583, 521,  93,  42, 237, 486,  97, 272, 416, 415,\n","         508, 293, 502, 500, 251,  60, 186, 553])}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"CuGO8lm1II7J"},"source":["## El modelo de clasificación\n","\n","Para clasificación utilizaremos un perceptrón multicapa de dos capas ocultas. Claramente este modelo es naive y prácticamente todo lo que está *hardcodeado* (e.g. los tamaños de las capas o la cantidad de capas) podría ser parte de los parámetros del modelo. En particular, tenemos la capa de `Embeddings` que es rellenada con los valores de embeddings preentrenados."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0qwAqKtdHu9","executionInfo":{"elapsed":699,"status":"ok","timestamp":1616158194167,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"329be067-e767-4917-bbce-e3dff9a11eb0"},"source":["!head ./data/SBW-vectors-300-min5.txt "],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000653 300\n","de -0.029648 0.011336 0.019949 -0.088832 -0.025225 0.056844 0.025473 0.014068 0.163694 -0.067154 0.014738 0.027134 0.066443 -0.044846 -0.044987 -0.040898 0.030311 0.034196 -0.049240 0.008537 -0.068091 -0.087938 0.035300 0.149385 -0.012350 0.012613 0.029350 0.069596 0.039111 0.057652 0.069954 -0.066217 -0.041784 0.028623 0.026772 -0.066392 0.002953 -0.012188 -0.030363 0.040222 0.034858 0.027469 -0.029034 -0.048748 -0.038582 -0.051553 -0.033501 -0.019008 0.003043 0.110712 -0.025096 0.111082 0.035244 0.114207 0.010195 0.051511 -0.040649 -0.113944 0.044873 0.052011 0.067360 0.049054 -0.127085 -0.031846 0.032848 0.040825 -0.084873 0.059801 -0.067424 0.016531 -0.084565 0.057024 0.083288 -0.010136 -0.048508 0.051757 0.046664 0.018102 -0.052320 -0.000765 0.053662 -0.009967 0.082858 0.009068 0.054575 -0.003466 -0.023376 0.023069 0.088513 0.018504 -0.039503 -0.032980 -0.002139 0.000010 -0.107627 0.007699 0.046351 -0.003062 0.030500 0.113650 0.032536 -0.097301 -0.013734 0.098345 0.080898 -0.064173 -0.008874 -0.144751 0.037585 0.013290 0.059674 0.006163 0.007318 0.000053 -0.060292 -0.059135 0.049497 -0.011438 -0.095108 -0.043465 0.048567 -0.043990 -0.030774 0.005092 -0.032265 0.009392 0.018503 0.084857 0.109709 -0.020662 0.017696 0.026699 -0.076638 -0.014106 -0.035155 0.046999 -0.003727 -0.047805 0.044270 0.011314 0.036524 -0.069505 -0.014850 -0.003538 -0.047049 0.029349 0.034521 -0.032199 0.116497 -0.077610 0.068234 -0.016126 -0.066454 -0.079914 -0.020723 -0.064905 0.069560 0.021368 -0.049497 -0.046599 0.067663 -0.069035 0.118015 0.027463 -0.006176 -0.034514 -0.026515 0.040308 0.091113 -0.080539 0.132408 -0.070958 0.019730 0.033399 0.003489 -0.159659 -0.004230 0.004888 -0.056615 0.061021 0.025117 0.099613 0.063876 -0.006202 -0.049316 -0.020530 0.008522 -0.094168 -0.009451 -0.034682 -0.026801 0.065383 0.042528 -0.013688 0.035068 0.119803 -0.020278 0.111882 -0.068336 0.050245 -0.123240 0.002248 0.010229 -0.062540 -0.017837 -0.115210 0.051036 0.026920 0.083457 0.062902 0.003083 -0.037112 -0.015425 0.001716 0.018002 0.101100 0.019446 0.074839 0.059951 0.072243 -0.025459 -0.039853 0.077950 0.060199 -0.070603 0.060652 0.023855 -0.035858 -0.058043 -0.075130 0.000670 0.082828 -0.013141 0.144692 -0.105775 0.087624 0.047030 -0.015700 -0.042360 0.026337 0.144966 0.021922 0.012097 -0.011443 -0.110208 0.009333 -0.081423 -0.027137 0.000827 0.085389 0.034464 0.032338 -0.015040 0.009954 -0.011759 -0.042395 -0.000467 0.055047 -0.049710 -0.104978 0.031742 0.037020 -0.007016 -0.049712 0.041684 0.018348 -0.001201 0.019282 0.005763 0.074952 -0.018588 0.016055 0.119526 -0.014613 0.020598 0.027312 0.024252 -0.024044 -0.026332 -0.063152 -0.095363 -0.034335 -0.062552 -0.035730 0.091165 0.009686 0.020341 -0.012004 0.011826 -0.084301 0.011144 0.074969 -0.004862 -0.014076 0.025692 -0.077322 -0.022998 -0.128057 -0.004917 0.062628\n","DIGITO -0.013002 -0.000781 0.032629 -0.088482 0.021298 0.039986 0.068380 0.006264 0.091135 0.000434 0.009331 0.028423 0.020692 -0.013583 -0.032420 0.024689 0.033696 -0.023145 -0.035633 -0.010274 -0.081628 -0.053617 0.051587 0.091048 -0.016919 0.033980 0.073040 0.100553 0.027454 0.053528 -0.013338 -0.055065 -0.045165 0.053637 0.017824 -0.010603 0.013005 -0.002873 -0.069372 0.008059 -0.001416 0.012431 -0.080941 -0.065539 0.007878 -0.021076 -0.035602 -0.049555 0.048422 0.104744 -0.054366 0.018188 0.031350 0.098584 0.094406 0.019084 -0.033111 -0.092422 0.058111 0.042169 0.009418 0.052326 -0.076443 -0.065708 0.039609 0.070779 -0.104470 0.016466 -0.100397 -0.012615 -0.062208 0.044405 0.040897 0.047476 -0.010739 0.005267 0.081850 0.034962 -0.094599 0.015806 0.040549 -0.003756 0.036048 0.022974 0.035902 0.023096 0.039259 -0.016199 0.043539 0.014725 -0.006119 -0.018587 -0.014097 -0.002395 -0.134557 0.041796 0.001652 0.058954 0.078891 0.114630 0.105141 -0.128402 -0.066549 0.079760 0.024396 -0.113124 -0.001198 -0.135299 0.037189 -0.035586 0.094150 0.018785 -0.005085 -0.018881 -0.115887 -0.082005 0.024251 -0.033302 -0.078087 -0.022660 0.007569 -0.096935 -0.023436 -0.023365 -0.026818 -0.023903 0.046716 0.047488 0.067228 -0.033471 0.038515 0.023762 -0.125687 0.042650 -0.000855 0.001957 -0.052234 -0.066039 0.082063 0.001344 -0.009984 -0.117670 -0.004480 -0.006035 -0.006549 0.032035 -0.021916 -0.028900 0.087054 -0.103109 0.033930 -0.036428 0.002393 -0.009741 -0.069586 -0.020493 0.001128 -0.067282 -0.043965 -0.075068 0.099662 -0.017608 0.066231 -0.015208 0.031142 -0.027223 -0.033040 0.053951 0.046496 -0.131409 0.131169 -0.007959 -0.011152 0.000514 -0.028036 -0.168291 -0.022996 -0.032068 -0.039740 0.016381 0.005333 0.099232 0.051381 -0.000236 -0.073249 0.012495 -0.015802 -0.091128 -0.003723 -0.022181 -0.046669 0.059063 0.064704 0.028548 0.011399 0.117871 -0.028101 0.068917 0.008404 0.030469 -0.104959 0.002380 -0.040827 0.041906 -0.024125 -0.046123 0.006722 0.074472 0.107256 0.066871 -0.017771 -0.007295 -0.007886 -0.031781 0.050508 0.043651 -0.043853 0.119111 0.048094 0.027306 -0.012738 -0.055844 0.000362 0.073290 -0.094030 0.088980 0.033241 -0.082521 -0.114527 -0.077395 -0.057670 0.046407 0.032855 0.090644 -0.084556 0.130570 0.046755 -0.000518 -0.062754 0.003713 0.142896 -0.000069 0.012594 -0.018961 -0.071201 -0.050190 -0.107127 -0.011871 0.030770 0.038137 0.023721 0.028529 0.065621 0.018548 0.044810 -0.023708 0.028006 0.028420 0.000359 -0.051305 0.035992 0.077839 -0.046144 -0.010108 0.056583 0.040588 0.106301 0.046546 -0.028884 0.031776 -0.023081 0.011159 0.058000 -0.002292 -0.021265 0.030547 -0.046024 0.021797 0.090825 -0.097326 -0.077190 0.060535 -0.078626 -0.108777 0.048595 -0.039361 0.022155 -0.015696 0.007409 -0.130169 0.048188 0.095554 -0.007935 -0.010960 0.009057 -0.055717 -0.016302 -0.132496 0.029352 0.063434\n","la -0.022313 0.022251 0.036704 -0.096540 -0.052861 0.024058 0.011043 0.002622 0.156215 -0.042965 0.039763 -0.003066 0.038801 -0.053368 -0.041667 -0.030635 -0.007328 0.003714 -0.114164 -0.025042 -0.051972 -0.055420 0.042268 0.105376 -0.060363 -0.019926 -0.001696 0.102281 0.040454 0.088647 0.088293 -0.019142 0.003859 -0.027580 0.018365 -0.088503 -0.011589 -0.052447 -0.008289 -0.020715 0.009673 0.012709 -0.082492 -0.040010 -0.057307 -0.087804 -0.020654 0.018062 0.034962 0.131913 -0.033211 0.130602 0.014101 0.057181 0.005193 0.058847 -0.062297 -0.131932 0.017364 0.088293 0.053714 0.019530 -0.121452 0.018164 0.060706 0.088240 -0.059637 0.037769 -0.052032 0.079613 -0.133862 -0.006583 0.068153 0.041149 -0.059254 0.057758 0.010501 0.058813 -0.026589 -0.078938 0.032387 -0.010713 0.054048 0.016489 0.052541 0.019058 -0.035579 0.035734 0.079074 0.027151 -0.034716 -0.041740 0.027742 0.038502 -0.131790 0.000054 0.023742 -0.015529 -0.016263 0.074132 -0.034666 -0.074852 0.005035 0.113395 0.032837 0.004166 0.004269 -0.135889 0.062360 0.051681 0.044063 0.054768 0.067986 0.032836 -0.095447 -0.072281 0.028622 0.029793 -0.057763 -0.034192 0.001806 -0.043905 -0.044698 0.007713 -0.047600 0.014539 -0.004542 0.047801 0.049999 -0.044603 0.038886 0.022660 -0.053500 -0.062190 -0.085413 0.072058 0.029248 -0.031418 -0.055516 0.025744 0.060207 -0.014266 -0.022034 0.018754 -0.015960 -0.001577 0.020190 -0.069271 0.138597 -0.101960 0.043598 0.005266 -0.075013 -0.063113 0.049575 -0.053393 0.043651 0.012303 -0.034139 0.024200 0.055642 -0.030245 0.100529 -0.017504 -0.060918 -0.100398 -0.043245 0.047509 0.040789 -0.048056 0.107280 -0.079895 0.049304 0.028526 0.040193 -0.097320 -0.000557 0.004501 -0.000329 0.006951 0.037162 0.053592 0.071350 0.025196 -0.031765 -0.000354 -0.013615 -0.080432 0.026182 -0.030302 -0.028832 -0.002504 0.071907 -0.027518 0.008791 0.142758 0.008447 0.099430 -0.051668 0.107455 -0.098141 -0.060972 -0.013618 -0.041751 0.039856 -0.068698 0.027978 -0.026681 0.034578 0.036537 -0.019795 0.007946 0.014677 -0.028922 0.026407 0.100824 0.024597 0.057108 0.026002 0.004507 0.008445 -0.070869 0.119097 0.036694 0.017460 0.024830 0.049018 -0.042634 -0.075510 -0.044751 0.038456 0.074046 -0.046579 0.143879 -0.062126 0.027630 0.072420 -0.044438 -0.066515 0.036794 0.196606 0.001752 0.048581 0.016231 -0.133789 0.010679 -0.072775 -0.007094 -0.010939 0.084204 0.018636 0.107546 -0.044642 0.017310 -0.013498 0.008038 0.006861 0.067795 -0.064582 -0.110481 0.034113 0.054558 -0.020856 -0.100647 0.049993 0.001914 -0.059515 0.010465 0.000765 0.135641 -0.019326 0.037263 0.065312 0.008730 0.007405 0.044418 0.038109 -0.022185 -0.045651 -0.064789 -0.119470 0.002855 -0.037815 -0.011621 0.034758 0.026737 0.077853 -0.000177 -0.009866 -0.037531 0.018481 0.067658 0.005637 -0.034123 0.003338 -0.062329 -0.016266 -0.087151 -0.020682 0.033452\n","en 0.026581 -0.015241 0.076188 -0.033951 -0.005532 0.040253 0.014638 -0.026969 0.174926 -0.088551 0.030411 0.033171 0.035247 -0.053153 0.034791 -0.043782 0.021706 -0.001933 -0.030657 0.056735 -0.096816 -0.006083 0.023477 0.129903 -0.089923 -0.012156 0.023389 0.076864 0.075134 0.061423 -0.033565 -0.045924 -0.083673 -0.004397 0.049242 -0.100869 0.010767 0.014354 -0.034536 0.006054 0.009703 0.028443 0.024843 -0.085018 -0.013708 -0.019241 -0.018230 -0.026206 0.021970 0.041291 -0.083791 0.088205 0.029461 0.129968 -0.035930 0.045489 0.000100 -0.036779 0.058822 0.096341 -0.068487 0.093272 -0.054641 -0.054127 0.049860 0.047078 -0.081942 0.131879 -0.056536 0.035574 -0.161969 -0.015891 0.072931 0.002060 -0.062984 0.037286 -0.021168 0.058015 0.000511 -0.088004 0.025141 -0.032483 0.043571 -0.014221 0.059971 0.017288 0.009931 -0.003049 0.045414 0.030266 -0.041036 -0.038548 0.055262 -0.010400 -0.109452 0.040224 0.049651 -0.005717 0.069147 0.079641 0.037132 -0.083692 -0.032963 0.086437 0.042587 -0.088681 0.004317 -0.112368 0.047439 0.046220 0.047233 0.052244 0.040376 0.043803 0.003122 -0.049596 0.105030 0.051798 -0.089496 -0.061939 0.064500 -0.006850 -0.033281 -0.007044 -0.059802 0.001478 0.061763 -0.005635 0.072320 0.026220 0.038630 0.061924 -0.040747 0.001671 -0.076976 0.062713 -0.003883 -0.075068 0.037281 -0.001749 -0.015784 -0.073255 -0.041658 -0.015254 -0.083932 0.019675 0.023857 0.011877 0.110891 -0.126212 0.008916 0.022912 -0.086664 -0.052335 -0.025554 -0.082052 0.059955 0.010351 -0.052768 -0.022825 0.066495 -0.018831 0.036371 -0.010668 -0.001757 -0.043319 -0.002546 0.014011 0.065008 -0.063852 0.143000 -0.017950 -0.012133 0.034645 0.019249 -0.120813 -0.028476 -0.027132 -0.052217 0.034275 0.056875 0.091684 0.104272 0.047259 -0.076129 0.012061 0.001202 -0.066170 -0.023275 -0.037404 -0.039282 0.047298 0.018953 -0.063144 0.013522 0.151888 0.036871 0.059711 -0.048100 0.068195 -0.123619 -0.022605 -0.037766 0.001217 -0.011442 -0.072790 0.090778 -0.003909 0.109163 0.001483 -0.010494 -0.035323 -0.089491 0.032565 0.064478 0.099495 -0.004145 0.062221 -0.002344 0.075857 0.025798 -0.058230 0.106080 -0.037642 -0.098980 0.040896 0.050060 -0.025803 -0.076346 -0.031277 -0.016458 0.074173 -0.017541 0.117265 -0.054809 0.071285 0.034627 0.018742 0.003090 -0.022064 0.079526 -0.036521 0.059427 0.023826 -0.088483 -0.053345 -0.031825 -0.091163 -0.000318 0.097550 0.039705 0.068879 0.009346 -0.005831 -0.020445 -0.037551 -0.030627 0.042611 -0.060933 -0.061835 -0.025218 0.054502 0.007813 0.007886 -0.096371 0.032693 -0.074697 -0.022726 0.027068 0.093267 0.027991 0.016513 0.021966 -0.001403 0.004168 0.007359 0.020973 -0.011663 -0.058841 -0.039689 -0.021151 0.001391 0.017551 -0.019631 0.078555 0.038571 0.063819 -0.028779 -0.015407 -0.119639 0.054226 0.097685 -0.000983 0.013433 0.002072 -0.135137 0.039641 -0.113613 -0.082998 0.001794\n","el -0.019094 -0.054838 0.061867 -0.032082 -0.005957 0.057351 0.028500 -0.043159 0.151103 -0.047987 -0.065501 0.019325 0.045845 -0.052837 0.039334 -0.029077 -0.035610 0.005154 0.007917 0.039476 -0.063586 -0.041226 0.022597 0.088539 -0.047592 0.006095 0.068421 0.040141 0.071777 0.052399 0.018608 -0.104608 -0.065750 0.057864 0.026319 -0.014900 -0.030556 -0.020601 -0.048309 0.018427 0.027275 -0.011767 -0.054502 -0.074528 -0.051803 -0.087762 -0.006023 -0.003563 0.068748 0.039145 -0.043258 0.041879 0.057915 0.095341 0.018489 -0.001705 -0.028376 -0.071598 0.083582 0.060199 0.007671 0.059488 -0.004180 -0.009021 0.029272 0.041644 -0.096565 0.086306 -0.086528 -0.047175 -0.090746 0.050310 0.041464 0.022899 -0.048404 0.051755 0.018348 0.000737 -0.072073 0.000742 0.045431 0.031756 0.056730 -0.002922 -0.029613 -0.064712 0.031082 -0.054350 0.015172 0.038507 0.005052 0.041152 0.017918 0.000021 -0.140041 -0.032220 0.045753 -0.001662 0.107630 0.056159 0.031969 -0.061976 -0.125508 0.099241 0.072667 -0.111275 -0.037890 -0.098337 0.009009 0.032999 0.108232 0.001456 -0.019507 0.021065 -0.070871 -0.067959 0.087397 -0.017634 -0.071713 -0.068235 0.021910 -0.036611 -0.056015 0.002406 -0.000682 0.002840 -0.004956 0.051061 0.039282 -0.004243 0.068350 0.078494 -0.111187 0.001789 -0.050798 0.043564 0.022463 -0.079984 0.083845 -0.039942 -0.002670 -0.105963 -0.045711 -0.070839 -0.071386 0.018530 0.030352 -0.022617 0.052608 -0.076264 0.054236 0.038974 -0.065505 -0.016966 -0.054466 -0.047889 0.059159 -0.038347 -0.046825 -0.067137 0.054917 -0.048225 0.112417 -0.059300 0.042382 0.061968 -0.016934 -0.006549 0.058622 -0.070197 0.136546 -0.029121 -0.021011 0.032252 0.013837 -0.144404 -0.032138 0.016345 0.003643 0.095301 0.035812 0.078058 0.078509 0.010083 -0.038933 0.017821 0.012711 -0.035441 -0.045516 -0.031174 -0.020619 0.071923 0.066945 -0.024285 0.008731 0.103420 -0.026585 0.086919 0.023265 0.087532 -0.169808 0.010314 -0.009849 -0.010514 -0.061712 -0.096139 0.056519 0.031146 0.120540 0.121889 -0.001435 -0.050902 -0.057896 0.043951 0.011844 0.071470 -0.034592 0.100551 0.028934 0.082797 -0.004083 -0.063326 0.057935 0.049082 -0.086728 0.055341 0.046598 -0.037046 -0.078920 -0.088477 -0.012546 0.063808 0.001957 0.098891 -0.114209 0.085782 0.031362 0.005591 -0.011783 0.052346 0.146943 -0.034617 -0.000501 -0.072018 -0.076500 -0.018684 -0.048509 -0.055089 0.008249 0.056943 0.080161 0.038735 0.055476 -0.023171 0.018044 -0.076114 0.039769 0.004626 -0.057135 -0.057441 0.029075 0.029289 0.001732 -0.040982 -0.019653 -0.000673 0.052067 0.025087 -0.015553 0.031290 -0.015537 0.026309 0.040171 0.015795 -0.004143 0.009772 0.017129 0.007851 -0.024184 -0.079634 -0.091227 0.027483 -0.015121 -0.004996 0.076148 -0.001744 0.029846 -0.000951 -0.032178 -0.145940 -0.009878 0.118325 0.003628 -0.082544 -0.026749 -0.075919 -0.043725 -0.132087 -0.024071 0.061029\n","y -0.042121 -0.037836 0.036679 -0.084050 0.006515 0.099305 0.045928 0.016368 0.134327 -0.011844 0.010659 0.034676 0.077137 -0.029783 -0.037907 -0.013795 -0.006836 0.011500 -0.076058 0.024434 -0.001108 -0.066514 0.038872 0.112885 -0.029406 0.007112 0.051488 0.107979 0.017522 0.092438 0.023222 -0.085683 -0.027921 0.007972 -0.025705 -0.028533 -0.024607 0.021877 -0.012343 0.042430 -0.007043 -0.024389 -0.024505 -0.033911 -0.057083 -0.084533 0.016485 -0.036139 -0.016978 0.102030 0.009303 0.075448 0.002156 0.139538 0.030210 0.044145 0.018690 -0.052760 0.077810 -0.005391 0.002815 0.053274 -0.115534 -0.051825 0.087068 0.077077 -0.135340 0.059492 -0.101219 -0.022589 -0.096890 0.007034 0.100118 -0.027093 -0.035940 0.036322 0.068001 0.009856 -0.060712 0.009975 0.052419 0.007922 0.040131 -0.043593 0.044140 -0.070362 -0.023544 0.007764 0.046340 -0.002144 -0.032538 -0.036125 0.072541 0.031860 -0.079002 -0.008596 0.030342 0.031109 0.049772 0.098390 0.028766 -0.087979 -0.026243 0.101731 0.096011 -0.098713 -0.028484 -0.124418 0.012567 0.059454 0.058859 0.045594 0.042404 0.058988 -0.027370 -0.039773 0.079016 0.075955 -0.081528 -0.040563 0.003863 -0.025793 -0.064998 -0.012341 -0.044403 0.032571 0.032722 0.063099 0.043915 0.008649 0.011968 -0.003642 -0.048209 -0.004967 -0.009467 0.047431 -0.039778 -0.087145 0.067849 0.015591 0.042563 -0.063274 -0.016025 -0.012975 -0.007136 0.003320 0.031884 -0.025658 0.170790 -0.064511 0.087716 -0.012953 -0.089275 -0.078927 -0.040504 -0.049050 0.046049 -0.073238 -0.034384 -0.029562 0.058786 -0.048790 0.104966 0.006574 0.024187 -0.034967 -0.042244 0.044918 0.033789 -0.087381 0.144220 -0.079357 -0.044999 0.041973 0.063769 -0.131122 -0.035932 0.019795 -0.015165 0.060755 0.067912 0.072251 0.045235 -0.050696 -0.032275 -0.042132 0.039258 -0.105867 0.026290 -0.035994 -0.017492 0.051305 0.026117 -0.010991 0.022200 0.092220 0.005362 0.100001 -0.069541 0.028063 -0.072846 -0.025222 -0.052707 -0.013893 0.016668 -0.090094 0.079421 0.010554 0.104492 0.043973 -0.047725 -0.053228 -0.038448 0.047978 0.009977 0.071996 0.051516 0.056524 0.044401 -0.007176 -0.012876 -0.036896 0.107779 0.057859 -0.027401 0.059532 0.055896 -0.036159 -0.130574 -0.082946 -0.010875 0.065847 -0.037720 0.049972 -0.087733 0.099261 0.010922 -0.069056 -0.063673 0.045537 0.156079 -0.001204 -0.002200 -0.049615 -0.124501 -0.003060 -0.039126 -0.057013 0.002022 0.077750 0.057647 -0.002259 0.032134 0.039760 -0.044032 -0.016928 0.031718 0.030675 -0.045675 -0.062055 0.074004 0.091850 -0.008636 -0.047515 0.042973 -0.022288 0.069358 0.024483 -0.063722 0.062641 -0.050236 0.056393 0.043446 0.026321 -0.001066 -0.005073 0.049178 -0.005089 -0.002601 -0.024335 -0.103959 -0.028944 -0.074412 0.000756 0.073722 -0.009733 -0.024274 0.032052 -0.010659 -0.116662 -0.022428 0.087131 -0.009682 -0.027912 -0.000686 -0.100404 0.039308 -0.109681 0.018647 0.034145\n","que -0.002689 -0.063456 0.009619 -0.075912 0.002579 0.025287 -0.051774 -0.015810 0.161642 -0.062808 -0.013864 -0.009856 0.045704 -0.074680 0.051135 -0.017151 -0.003561 -0.001276 -0.077127 0.016603 0.011733 -0.048739 0.039748 0.054235 -0.036468 -0.052945 -0.006031 0.099651 -0.028718 0.075966 0.054379 -0.039412 -0.027434 -0.010707 0.029061 -0.011958 -0.027064 -0.033164 -0.091794 -0.039789 0.047586 0.037241 -0.009755 -0.005757 -0.060044 -0.005748 0.017914 0.022921 0.056237 0.094185 -0.056646 0.050965 -0.003328 0.137955 -0.024645 0.003999 -0.013210 -0.094191 0.029361 0.065217 -0.015854 0.050067 -0.016534 -0.014519 0.032965 0.030408 -0.115367 0.026486 -0.080514 -0.019257 -0.096709 -0.077588 0.060865 0.094164 -0.099619 0.132228 -0.083935 -0.011013 -0.068265 -0.014002 0.050748 0.036933 0.041567 -0.024340 -0.015914 -0.017347 0.029209 0.047102 0.070173 0.015551 -0.009812 -0.013571 0.127878 -0.032161 -0.074046 -0.092937 0.006629 0.002188 0.013948 0.083105 -0.054561 -0.098746 -0.050451 0.074982 0.071701 -0.027987 0.034169 -0.070208 0.024198 0.099134 0.083352 0.052365 0.074382 0.032819 -0.045973 -0.024529 0.080065 0.010117 -0.016776 -0.100084 -0.035398 0.066112 -0.072628 -0.007483 -0.120063 0.094598 -0.018094 -0.057935 0.061705 0.004589 0.074878 0.000203 -0.064027 -0.092381 -0.052254 0.102206 0.026677 -0.099442 0.030952 0.029867 0.026049 0.008899 -0.025673 -0.044990 0.005295 -0.016670 -0.010131 -0.047413 0.022243 -0.035623 -0.002019 0.009365 -0.062364 -0.056982 -0.020327 -0.031840 0.103263 0.026027 -0.033970 -0.000850 -0.055312 -0.024188 0.089656 -0.068503 0.014380 -0.008165 0.016037 0.025563 0.081804 -0.003454 0.157332 -0.132477 -0.000092 -0.019525 0.041020 -0.087384 -0.077959 -0.016578 0.014818 0.071696 0.093232 0.106681 0.075612 -0.053004 -0.030074 -0.039739 0.021461 -0.106232 0.007007 -0.021070 -0.057630 -0.024995 0.041227 -0.047074 -0.021664 0.055596 0.021923 0.076737 -0.019297 -0.090034 -0.123045 -0.000816 -0.086728 -0.014518 -0.005784 -0.063479 0.027065 0.002798 -0.011823 0.076236 -0.060856 -0.009606 -0.043855 -0.018248 0.008788 0.109807 -0.000731 0.119774 -0.064890 0.011259 -0.025940 0.010084 0.047275 0.039871 -0.079974 0.006294 0.047295 -0.022516 -0.123771 -0.043215 0.020200 -0.005444 0.022062 0.041229 -0.054759 0.028675 -0.016499 -0.066043 -0.067645 0.046606 0.174002 -0.046577 -0.034094 -0.016998 -0.127203 -0.015287 -0.048483 -0.063370 0.018057 0.067036 0.038760 -0.014682 0.003502 0.074684 -0.004579 0.012645 0.060375 0.011071 -0.104448 -0.023500 0.129327 0.108149 0.017028 -0.023761 0.013200 -0.106190 -0.081396 -0.000015 -0.073123 0.051081 0.000019 0.112538 -0.109238 0.037213 -0.006113 0.016891 0.071667 -0.012543 -0.043288 -0.030091 -0.005994 -0.042346 -0.055406 0.056610 0.022521 0.033848 0.024308 0.042734 -0.018096 -0.089446 -0.015459 0.061343 -0.036983 -0.013618 -0.024007 -0.111448 0.003092 -0.039190 0.026918 0.007546\n","a -0.085708 -0.014221 -0.028402 -0.041660 0.000841 0.026713 -0.070521 -0.020635 0.151278 -0.043035 0.022053 0.060899 0.027153 -0.020045 0.016947 -0.006727 -0.048576 0.028197 -0.077388 -0.012958 -0.032999 -0.085236 0.033298 0.048615 -0.062863 -0.086112 0.078298 0.099283 -0.029768 0.097277 0.035398 0.010830 0.036246 0.024329 0.000256 -0.053414 -0.051688 0.017490 0.033324 0.003499 0.060596 0.025377 -0.038630 0.003894 -0.061409 -0.050302 0.031621 -0.057430 0.021222 0.094447 -0.038353 0.095174 -0.028562 0.129691 0.016649 0.065995 0.017320 -0.112592 0.052304 0.015935 -0.013187 0.027251 -0.043155 0.004700 0.046635 0.035095 -0.106708 0.109668 -0.034918 -0.022885 -0.078081 -0.008696 0.087973 -0.021335 -0.038379 0.085882 0.074952 -0.031077 -0.032370 -0.024936 -0.064589 0.023546 0.056268 0.089660 0.048147 -0.001469 0.045662 0.114295 0.041474 0.009460 0.030381 -0.042455 0.094784 0.004791 -0.054252 -0.005596 0.077166 0.004340 0.032954 0.095851 -0.055361 -0.053738 0.025474 0.088548 0.048974 -0.012645 0.021798 -0.160509 -0.071003 0.078340 0.024732 0.044401 0.023484 0.014640 -0.105357 -0.072310 0.051115 -0.013979 -0.104898 -0.049686 -0.074997 -0.024003 0.002897 -0.016695 -0.005288 0.070059 0.042156 -0.026912 0.055670 -0.012965 0.023968 -0.028007 -0.098136 -0.066733 -0.033063 0.090629 0.050029 -0.036112 0.008000 -0.019124 0.001585 -0.050867 -0.057871 0.012271 0.054926 -0.073830 0.016126 -0.017341 0.162786 -0.051869 0.048271 -0.007905 -0.044899 -0.060555 -0.032798 -0.042563 0.007000 -0.041733 0.077264 -0.028744 0.041560 -0.043970 0.102608 -0.063534 -0.030251 -0.085311 -0.070170 0.032403 0.050852 -0.029692 0.204252 -0.081406 -0.014004 -0.027134 0.046173 -0.096796 -0.011267 -0.030390 -0.039823 0.016193 0.072762 0.002904 0.053425 -0.007085 -0.057839 -0.028737 0.005004 -0.108273 -0.028901 -0.014450 -0.011476 -0.047680 0.042957 -0.028786 -0.051833 0.174963 0.056555 0.066884 -0.012178 -0.079719 -0.134066 -0.003384 -0.059435 -0.041294 -0.016674 -0.065865 0.046402 0.054264 0.041868 0.019971 -0.049754 -0.066999 -0.010109 -0.018221 -0.007654 0.079747 0.059242 0.047878 -0.004967 0.016677 -0.033916 0.003234 0.063001 0.059698 -0.088501 0.090181 0.006319 -0.019144 -0.121754 -0.078249 0.030398 -0.024264 0.043136 -0.000854 -0.077675 0.086028 -0.010723 -0.096656 -0.013100 0.037266 0.169945 -0.026870 -0.013890 -0.032570 -0.088369 -0.025112 -0.031090 -0.023369 0.078204 0.026516 0.064645 0.065211 0.072346 0.016042 0.046019 -0.025140 -0.018420 0.004399 0.053585 -0.003360 0.045258 0.080729 0.021974 -0.083316 0.053740 0.004446 0.078119 -0.003585 -0.048441 0.038877 0.014348 0.064513 0.014956 -0.020856 0.001713 0.031545 0.040790 0.014643 -0.057416 0.017689 -0.084654 -0.092191 -0.033100 0.035180 -0.004986 -0.014108 -0.029003 0.028466 0.001388 -0.122391 -0.035286 -0.007954 0.007977 -0.062431 -0.016400 -0.084379 0.042604 -0.115474 -0.021421 0.056566\n","los -0.018489 0.036911 0.045592 -0.006009 0.009740 0.062708 -0.017418 0.000362 0.136461 -0.123914 0.004111 0.012575 0.051185 -0.015960 -0.007032 -0.060143 -0.086755 -0.001579 -0.072407 -0.001173 0.030028 -0.120873 -0.011749 0.103469 -0.095740 0.016945 -0.052293 0.100694 0.026250 0.051805 0.050285 0.007062 0.019713 0.007554 0.003000 -0.007825 0.031388 -0.053674 -0.070242 0.014803 0.031444 -0.015814 0.005966 -0.035825 -0.056899 -0.066460 -0.031974 -0.094435 0.044974 0.109062 -0.010704 0.083039 -0.007427 0.055845 0.072120 0.040261 -0.072686 -0.086832 0.128521 0.062262 0.005739 0.067721 -0.113566 0.034305 0.041693 0.072097 -0.079644 0.062137 -0.035381 0.021093 -0.122759 -0.002234 0.097428 0.017932 -0.095214 0.080814 0.048575 -0.002102 -0.046335 -0.005699 -0.059984 0.031422 0.061613 0.030816 0.026701 -0.068000 0.067893 -0.032332 0.077142 0.013572 -0.053096 -0.071081 0.125338 -0.021719 -0.113427 0.020651 0.011522 0.018410 0.005999 0.108815 -0.081018 -0.031712 -0.030261 0.104312 0.036996 -0.031590 -0.045709 -0.118326 -0.037217 0.066981 0.054778 0.082154 0.015319 0.039584 -0.004972 -0.059101 0.059792 0.038955 -0.029077 -0.059071 -0.062213 0.017934 -0.033466 0.007342 -0.096879 0.091667 0.032268 0.007647 -0.046322 -0.036875 0.071908 0.011096 -0.063519 -0.037783 -0.027381 0.077523 -0.041995 -0.110935 0.080467 -0.030527 -0.063902 -0.096758 0.026814 0.024715 -0.056444 0.002252 -0.038416 -0.075330 0.110978 -0.131945 -0.017590 -0.022661 -0.105336 -0.058229 -0.031346 -0.033111 0.068825 -0.005905 -0.013079 -0.078876 0.117026 -0.049613 0.081184 -0.047651 -0.006850 0.026761 -0.015042 0.040951 0.031432 -0.046367 0.082599 -0.087242 0.054085 0.010322 0.015893 -0.068361 -0.051342 -0.045214 0.012072 0.041920 0.056213 0.004658 0.074050 0.015432 -0.012290 0.062163 -0.001665 -0.170216 0.015962 -0.020238 -0.048876 0.023480 0.016153 -0.027302 -0.005531 0.012621 -0.002982 0.037035 -0.040416 0.029351 -0.088106 -0.107750 0.024803 -0.050490 -0.033057 -0.055477 0.083738 0.056245 0.051557 0.056413 -0.003753 -0.014272 -0.025381 -0.018004 -0.008878 0.067367 0.000718 0.038998 -0.004634 -0.003219 -0.026742 0.036714 0.025285 0.055854 -0.072501 0.044095 0.052553 0.014116 -0.062374 -0.056877 0.002491 0.014094 -0.060129 0.054998 -0.061254 0.071453 0.003723 -0.036329 -0.027158 0.003534 0.093185 0.007992 -0.097294 -0.036056 -0.102298 -0.041867 -0.141788 -0.068675 0.008443 0.075905 0.054666 -0.019575 0.066365 0.044702 -0.065557 0.021451 0.062475 0.099107 -0.039205 -0.115370 0.040057 0.140246 0.054609 -0.027473 -0.026007 -0.037904 0.008885 0.011040 -0.034092 0.068014 -0.005894 0.070370 0.054927 -0.000015 0.091078 0.005293 0.065675 0.013272 0.025433 0.014886 -0.078631 -0.010623 -0.032067 0.011527 0.052344 0.038192 -0.032623 -0.011271 -0.040584 -0.032548 -0.038051 0.079366 0.045388 -0.066945 -0.042741 -0.073721 -0.011892 -0.114976 0.025161 0.012087\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nT7qdd-Fe85o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Khywgk1Dfu4p"},"source":["# Multi-layer perceptron"]},{"cell_type":"code","metadata":{"id":"t47N4GGwII7K"},"source":["class MeliChallengeClassifier(nn.Module):\n","    def __init__(self, \n","                 pretrained_embeddings_path, \n","                 dictionary,\n","                 n_labels,\n","                 vector_size,\n","                 freeze_embedings):\n","        super().__init__()\n","        embeddings_matrix = torch.randn(len(dictionary), vector_size)\n","        embeddings_matrix[0] = torch.zeros(vector_size)\n","        with open(pretrained_embeddings_path, \"rt\") as fh:\n","            next(fh)\n","            for line in fh:\n","                word, vector = line.strip().split(None, 1)\n","                if word in dictionary.token2id:\n","                    embeddings_matrix[dictionary.token2id[word]] =\\\n","                        torch.FloatTensor([float(n) for n in vector.split()])\n","        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n","                                                       freeze=freeze_embedings,\n","                                                       padding_idx=0)\n","        self.hidden1 = nn.Linear(vector_size, 128)\n","        self.hidden2 = nn.Linear(128, 128)\n","        self.output = nn.Linear(128, n_labels)\n","        self.vector_size = vector_size\n","    \n","    def forward(self, x):\n","        x = self.embeddings(x)\n","        x = torch.mean(x, dim=1)\n","        x = F.relu(self.hidden1(x))\n","        x = F.relu(self.hidden2(x))\n","        x = self.output(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPSGw9uw575P","executionInfo":{"elapsed":795,"status":"ok","timestamp":1616161957534,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"f6405366-409a-4207-e5ed-ad595ab21b30"},"source":["hidden_layers = [256, 128, 64, 32]\n","list(zip(hidden_layers[:-1], hidden_layers[1:]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(256, 128), (128, 64), (64, 32)]"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"D7ShLLfKdlgK"},"source":["model = MeliChallengeClassifier(\"./data/SBW-vectors-300-min5.txt\", \n","                                preprocess.dictionary, \n","                                len(preprocess.target_to_idx) + 1,\n","                                300, True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mr2Hw3Eneh5h","executionInfo":{"elapsed":3641,"status":"ok","timestamp":1616161961142,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"60c6aaf9-9d20-4a9f-be23-fa8c37f16a89"},"source":["print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeliChallengeClassifier(\n","  (embeddings): Embedding(5634, 300, padding_idx=0)\n","  (hidden1): Linear(in_features=300, out_features=128, bias=True)\n","  (hidden2): Linear(in_features=128, out_features=128, bias=True)\n","  (output): Linear(in_features=128, out_features=605, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WUcg3T9cII7M"},"source":["## Experimento de MLflow\n","\n","Por último, ya tenemos todos los bloques para construir nuestro experimento de MLflow. Anotamos un par de parámetros  (estos pueden ser todos los que se consideren necesarios) y lanzamos a correr nuestro experimento. Cada vez que finaliza un epoch guardamos algunas métricas. Al finalizar todos los epochs corremos algunas métricas extras de evaluación y guardamos algunos datos extra que nos servirán para calcular otras métricas a futuro."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"_EOJk5tJII7N","executionInfo":{"elapsed":4448,"status":"error","timestamp":1616161964408,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"87c1a916-64c6-46e7-bbaa-0a363f51893e"},"source":["EPOCHS = 150\n","\n","mlflow.set_experiment(\"multilayer perceptron first attempt\")\n","\n","with mlflow.start_run():\n","    mlflow.log_param(\"model_name\", \"mlp\")\n","    mlflow.log_param(\"freeze_embedding\", True)\n","    mlflow.log_params({\n","        \"embedding_size\": 50,\n","        \"hidden1_size\": 128,\n","        \"hidden2_size\": 128\n","    })\n","    model = MeliChallengeClassifier(\"./data/SBW-vectors-300-min5.txt\", \n","                                    preprocess.dictionary, \n","                                    len(preprocess.target_to_idx) + 1,\n","                                    300, True)\n","    device = torch.device(\"cuda\")\n","    model = model.to(device)\n","    loss = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","    for epoch in trange(EPOCHS):\n","        model.train()\n","        running_loss = []\n","        for idx, batch in enumerate(tqdm(train_loader)):\n","            optimizer.zero_grad()\n","            data = batch[\"data\"].to(device)\n","            target = batch[\"target\"].type(torch.LongTensor).to(device)\n","            output = model(data)\n","            loss_value = loss(output, target)\n","            loss_value.backward()\n","            optimizer.step()\n","            running_loss.append(loss_value.item())        \n","        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n","        \n","        # Evaluación con los datos de validacion\n","        model.eval()\n","        running_loss = []\n","        targets = []\n","        predictions = []\n","        with torch.no_grad():\n","          for batch in tqdm(validation_loader):\n","            data = batch[\"data\"].to(device)\n","            target = batch[\"target\"].to(device)\n","            output = model(data)\n","            running_loss.append(\n","                loss(output, target).item()\n","            )\n","            targets.extend(batch[\"target\"].numpy())\n","            predictions.extend(output.argmax(axis=1).detach().cpu().numpy())\n","        mlflow.log_metric(\"validation_loss\", sum(running_loss) / len(running_loss), epoch)\n","        mlflow.log_metric(\"validation_bacc\", balanced_accuracy_score(targets, predictions), epoch)\n","\n","        # Evaluación con los datos de test\n","        model.eval()\n","        running_loss = []\n","        targets = []\n","        predictions = []\n","        with torch.no_grad():\n","          for batch in tqdm(test_loader):\n","            data = batch[\"data\"].to(device)\n","            target = batch[\"target\"].to(device)\n","            output = model(data)\n","            running_loss.append(\n","                loss(output, target).item()\n","            )\n","            targets.extend(batch[\"target\"].numpy())\n","            predictions.extend(output.argmax(axis=1).detach().cpu().numpy())\n","        mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n","        mlflow.log_metric(\"test_bacc\", balanced_accuracy_score(targets, predictions), epoch)\n","\n","\n","    \n","    with tempfile.TemporaryDirectory() as tmpdirname:\n","        targets = []\n","        predictions = []\n","        for batch in tqdm(test_loader):\n","            data = batch[\"data\"].to(device)\n","            target = batch[\"target\"].type(torch.LongTensor).to(device)\n","            output = model(data)\n","            targets.extend(target.cpu().detach().numpy())\n","            predictions.extend(output.squeeze().cpu().detach().numpy())\n","        pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n","            f\"{tmpdirname}/predictions.csv.gz\", index=False\n","        )\n","        mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO: 'multilayer perceptron first attempt' does not exist. Creating a new experiment\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-b905d5f26a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                     300, True)\n\u001b[1;32m     17\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}]},{"cell_type":"markdown","metadata":{"id":"BO__4V3KeRmk"},"source":["A pesar del error actual el código funciona. Se agotó el tiempo en Colab para correr con GPU. "]},{"cell_type":"code","metadata":{"id":"XC2R3uiGe71U"},"source":["!tar zcvf mlruns.tar.gz mlruns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Tj7eEY1hfpf","executionInfo":{"elapsed":2437,"status":"ok","timestamp":1616160035012,"user":{"displayName":"Alessio Bocco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi8GqrL-fSSQmpF5whKIns7BImyGZZGTtPdBxfvLQ=s64","userId":"05280155029653541179"},"user_tz":180},"outputId":"a73b9534-e0a4-4fe1-aa22-20e6cd9bcb13"},"source":["%%bash\n","\n","# Una vez que lo descargan, lo descomprimen en su máquina con el siguiente comando\n","tar xvf mlruns.tar.gz\n","\n","# Luego ejecutan en el lugar que lo descomprimieron lo siguiente\n","mlflow ui"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Process is interrupted.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cspjVrXiiQ97"},"source":[""],"execution_count":null,"outputs":[]}]}